{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NotLevente/yt-felirat/blob/main/youtube_magyar_felirat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Youtube feliratoz√≥**\n",
        "\n",
        "Ez az alkalmaz√°s az [OpenAI Whisper](https://openai.com/research/whisper) sz√∂vegfelismer≈ë technol√≥gi√°t haszn√°lva feliratot k√©sz√≠t magyar YouTube vide√≥khoz. Haszn√°lat√°hoz Google Chrome vagy MS Edge b√∂ng√©sz≈ë sz√ºks√©ges.\n",
        "---\n",
        "\n",
        "Futtatni a l√©p√©seket a \"Play\" gombok aktiv√°l√°s√°val lehet.\n",
        "\n",
        "**Els≈ë** l√©p√©sben let√∂lti √©s telep√≠ti a sz√ºks√©ges komponenseket. Ezt csak egyszer kell megtenni. Hab√°r 20 perc inaktivit√°s ut√°n az ingyenes Google colab t√∂rli a munkamenetet... Ha mag√°ra hagytad f√©l √≥r√°r√°ra √©s hib√°t jelez, futtasd √∫jra az els≈ë cell√°t.\n",
        "\n",
        "**M√°sodikban** Add meg a feliratozand√≥ video URL-t. Pl.: https://www.youtube.com/watch?v=suISpg_m-hw . Az elk√©sz√ºlt feliratf√°jl let√∂lt√©sre ker√ºl a videoazonos√≠t√≥.srt, jelen esetben suISpg_m-hw.srt n√©ven. \n",
        "\n",
        "\n",
        "\n",
        "A feliratot [ezzel a Chrome addonnal](https://chrome.google.com/webstore/detail/subtitles-for-youtube/oanhbddbfkjaphdibnebkklpplclomal?hl=en) lehet haszn√°lni.\n",
        "\n",
        "---\n",
        "\n",
        "K√∂zbeszerezve, magyaros√≠tva √©s egyszer≈±s√≠tve [innen](https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)."
      ],
      "metadata": {
        "id": "e4wedHUQLkYr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfG0E_WbRFI0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # **<-- 1. Hozz√°val√≥k el≈ëk√©sz√≠t√©se...** üèóÔ∏è\n",
        "#@markdown Kb. 2 perc am√≠g a f√ºgg≈ës√©geket telep√≠ti.\n",
        "\n",
        "\n",
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install yt-dlp\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "from google.colab import files\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "Model = 'large'\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "if Model in whisper.available_models():\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is selected.**\"\n",
        "    ))\n",
        "else:\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is no longer available.**<br /> Please select one of the following:<br /> - {'<br /> - '.join(whisper.available_models())}\"\n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **<-- 2. Video kiv√°laszt√°s √©s ind√≠t√°s** üöÄ\n",
        "\n",
        "#@markdown Add meg a feliratozand√≥ Youtube video URL-t.\n",
        "\n",
        "Type = \"Youtube video or playlist\"\n",
        "##@markdown ---\n",
        "##@markdown #### **Youtube video or playlist**\n",
        "URL = \"https://www.youtube.com/watch?v=suISpg_m-hw\" #@param {type:\"string\"}\n",
        "# store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown **Csak ezt a cell√°t futtasd √∫jra a ha egy m√°sik vide√≥t is feliratozn√°l.**\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    \n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "        'postprocessors': [{  # Extract audio using ffmpeg\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        error_code = ydl.download([URL])\n",
        "        list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "        \n",
        "    for video_info in list_video_info:\n",
        "        video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "            if video_path_drive.is_file():\n",
        "                display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "            elif video_path_drive.is_dir():\n",
        "                display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "            else:\n",
        "                display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "            video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "            shutil.copy(video_path_drive, video_path_local)\n",
        "            video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n",
        "\n",
        "##@markdown ### **Behavior control**\n",
        "##@markdown ---\n",
        "language = \"Hungarian\"\n",
        "##@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "##@markdown ---\n",
        "verbose = 'Live transcription'\n",
        "##@markdown > Whether to print out the progress and debug messages.\n",
        "##@markdown ---\n",
        "output_format = 'srt'\n",
        "##@markdown > Type of file to generate to record the transcription.\n",
        "##@markdown ---\n",
        "task = 'transcribe'\n",
        "##@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "##@markdown ---\n",
        "\n",
        "##@markdown <br/>\n",
        "\n",
        "##@markdown ### **Optional: Fine tunning** \n",
        "##@markdown ---\n",
        "temperature = 0.15 \n",
        "##@markdown > Temperature to use for sampling.\n",
        "#≈±@markdown ---\n",
        "temperature_increment_on_fallback = 0.2\n",
        "##@markdown > Temperature to increase when falling back when the decoding fails to meet either of the thresholds below.\n",
        "##@markdown ---\n",
        "best_of = 5 \n",
        "##@markdown > Number of candidates when sampling with non-zero temperature.\n",
        "##@markdown ---\n",
        "beam_size = 8\n",
        "##@markdown > Number of beams in beam search, only applicable when temperature is zero.\n",
        "##@markdown ---\n",
        "patience = 1.0 \n",
        "##@markdown > Optional patience value to use in beam decoding, as in [*Beam Decoding with Controlled Patience*](https://arxiv.org/abs/2204.05424), the default (1.0) is equivalent to conventional beam search.\n",
        "##@markdown ---\n",
        "length_penalty = -0.05 \n",
        "##@markdown > Optional token length penalty coefficient (alpha) as in [*Google's Neural Machine Translation System*](https://arxiv.org/abs/1609.08144), set to negative value to uses simple length normalization.\n",
        "##@markdown ---\n",
        "suppress_tokens = \"-1\" \n",
        "##@markdown > Comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations.\n",
        "##@markdown ---\n",
        "initial_prompt = \"\" \n",
        "##@markdown > Optional text to provide as a prompt for the first window.\n",
        "##@markdown ---\n",
        "condition_on_previous_text = True \n",
        "##@markdown > if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop.\n",
        "##@markdown ---\n",
        "fp16 = True \n",
        "##@markdown > whether to perform inference in fp16.\n",
        "##@markdown ---\n",
        "compression_ratio_threshold = 2.4 \n",
        "##@markdown > If the gzip compression ratio is higher than this value, treat the decoding as failed.\n",
        "##@markdown ---\n",
        "logprob_threshold = -1.0 \n",
        "##@markdown > If the average log probability is lower than this value, treat the decoding as failed.\n",
        "##@markdown ---\n",
        "no_speech_threshold = 0.6\n",
        "##@markdown > If the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence.\n",
        "##@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': True,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "args = dict(\n",
        "    language = (None if language == \"Auto detection\" else language),\n",
        "    verbose = verbose_lut[verbose],\n",
        "    task = task,\n",
        "    temperature = temperature,\n",
        "    temperature_increment_on_fallback = temperature_increment_on_fallback,\n",
        "    best_of = best_of,\n",
        "    beam_size = beam_size,\n",
        "    patience=patience,\n",
        "    length_penalty=(length_penalty if length_penalty>=0.0 else None),\n",
        "    suppress_tokens=suppress_tokens,\n",
        "    initial_prompt=(None if not initial_prompt else initial_prompt),\n",
        "    condition_on_previous_text=condition_on_previous_text,\n",
        "    fp16=fp16,\n",
        "    compression_ratio_threshold=compression_ratio_threshold,\n",
        "    logprob_threshold=logprob_threshold,\n",
        "    no_speech_threshold=no_speech_threshold\n",
        ")\n",
        "\n",
        "temperature = args.pop(\"temperature\")\n",
        "temperature_increment_on_fallback = args.pop(\"temperature_increment_on_fallback\")\n",
        "if temperature_increment_on_fallback is not None:\n",
        "    temperature = tuple(np.arange(temperature, 1.0 + 1e-6, temperature_increment_on_fallback))\n",
        "else:\n",
        "    temperature = [temperature]\n",
        "\n",
        "if Model.endswith(\".en\") and args[\"language\"] not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{args['language']}'; using English instead.\")\n",
        "    args[\"language\"] = \"en\"\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    display(Markdown(f\"### {video_path_local}\"))\n",
        "\n",
        "    video_transcription = whisper.transcribe(\n",
        "        whisper_model,\n",
        "        str(video_path_local),\n",
        "        temperature=temperature,\n",
        "        **args,\n",
        "    )\n",
        "\n",
        "    # Save output\n",
        "    whisper.utils.get_writer(\n",
        "        output_format=output_format,\n",
        "        output_dir=video_path_local.parent\n",
        "    )(\n",
        "        video_transcription,\n",
        "        str(video_path_local.stem),\n",
        "        options=dict(\n",
        "            highlight_words=False,\n",
        "            max_line_count=None,\n",
        "            max_line_width=None,\n",
        "        )\n",
        "    )\n",
        "    try:\n",
        "#        if output_format==\"all\":\n",
        "#            for ext in ('txt', 'vtt', 'srt', 'tsv', 'json'):\n",
        "#                transcript_file_name = video_path_local.stem + \".\" + ext\n",
        "#                shutil.copy(\n",
        "#                    video_path_local.parent / transcript_file_name,\n",
        "#                    drive_whisper_path / transcript_file_name\n",
        "#                )\n",
        "#                display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "#        else:\n",
        "            transcript_file_name = video_path_local.stem + \".\" + output_format\n",
        "            subfil = video_path_local.parent / transcript_file_name\n",
        "            files.download(subfil) \n",
        "#            shutil.copy(\n",
        "#                video_path_local.parent / transcript_file_name,\n",
        "#                drive_whisper_path / transcript_file_name\n",
        "#            )\n",
        "#            from google.colab import files\n",
        "#            files.download(video_path_local.parent / transcript_file_name) \n",
        "#            display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "\n",
        "    except:\n",
        "        display(Markdown(f\"**Transcript file created: {transcript_local_path}**\"))"
      ],
      "metadata": {
        "id": "xYLPZQX9S7tU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}